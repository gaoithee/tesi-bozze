{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ed6246-e9aa-4fbc-a775-dc25888cdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "from guidance import models, select\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583be627-ea69-4520-ada3-67713ac6ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text(text):\n",
    "    return re.sub(r\"[^\\w\\s.,!?\\-:;()]+\", '', text)\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text_final(text):\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"\\-:;()]+', '', text)  # Rimuove i caratteri speciali\n",
    "    text = re.sub(r\"['\\\"-]\", '', text)  # Rimuove apostrofi, virgolette e trattini\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd823455-1bb7-47e3-8c28-8632f236ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt augmentation for the (format of the) synthesis:\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"You are a multiple-choice question answering assistant.\n",
    "Choose the most proper option between {options} that best matches with the suggestion. \n",
    "\n",
    "Question: {question}\n",
    "Context: {critique}\n",
    "Sources: {context}\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    ")\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"options\": itemgetter(\"options\"), \n",
    "                \"critique\": itemgetter(\"critique\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "synthesis_chain = augmentation | prompt_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96c0705-1b51-45d0-8ba1-2a4cae245196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_thesis(question, options, context):\n",
    "    options_str = '\", \"'.join(options)\n",
    "    content = f\"\"\"\n",
    "\n",
    "    Now do the same for this question: \"{question}\", where options: [\"{options_str}\"]. Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = \"Answer to the following question: \" + question + \" providing one of these options as answer: \" + str(options) + \"Assistant:\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You have to provide helpful answers to the user’s questions based on the context: \n",
    "        \"\"\" + context},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def extract_answer_thesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"}]\")\n",
    "\n",
    "    \n",
    "    # Se l'indice è stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"}]\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\"\n",
    "\n",
    "def thesisGeneration(query, merged, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = create_message_thesis(query, merged, sources)\n",
    "    ans = new_model + str(augmented_prompt) + select(merged)\n",
    "    return str(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0adcaf-24b7-46ba-9eed-021f0c4215c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_antithesis(question, candidate, options, context):\n",
    "    options_str = '\", \"'.join(options)\n",
    "    content = f\"\"\"\n",
    "\n",
    "    Now do the same for this question: \"{question}\", where options: [\"{options_str}\"]. Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = \"Question: \" + question + \"\\n Options: \" + str(options) + \"\\n Candidate answer: \" + candidate + \"\\n Context: \" + context + \"\\n Assistant: \\n\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You are asked to determine the most correct answer for a given question, provided a set of possible options.\n",
    "        You also have at disposal a first tentative answer that you are required to check with respect to the question and the relevant context.\n",
    "        Your goal is to decree which is the most correct answer to the question between the available options.\n",
    "\n",
    "        Here's an example of how to do it:\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "        Question: What is the sun, a star or a planet?\n",
    "        Options: ['a star', 'a planet']\n",
    "        Candidate answer: a planet\n",
    "        Context: The Sun is the star at the center of the Solar System. It is a massive, nearly perfect sphere of hot plasma, heated to incandescence by nuclear fusion reactions in its core, radiating the energy from its surface mainly as visible light and infrared radiation with 10% at ultraviolet energies.\n",
    "\n",
    "        Assistant: The correct answer should be 'a star' due to the fact that the context explicitly say so. On the opposite, the context never mentions the fact that the Sun could be a planet.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\"role\": \"system\", \"content\": \"Now do the same for the following question:\"},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def antithesisGeneration(query, merged, candidate, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    prompt = create_message_antithesis(query, candidate, merged, sources)\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507e20fb-b0f7-47ab-92db-836c9a4d5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_presynthesis(question, candidate, suggestion, options, context):\n",
    "\n",
    "    user_content = \"Question: \" + question + \"\\n Options: \" + str(options) + \"\\n Candidate answer: \" + candidate + \"\\n Suggestion: \" + suggestion + \"\\n Context: \" + context + \"\\n Assistant: \\n\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You are asked to determine the most correct answer for a given question, provided a set of possible options.\n",
    "        You also have at disposal a first tentative answer and a suggestion on which is the correct answer.\n",
    "        Your goal is to decree which is the most correct answer to the question between the available options according to the context.\n",
    "\n",
    "        Here's an example of how to do it:\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "        Question: What is the sun, a star or a planet?\n",
    "        Options: ['a star', 'a planet']\n",
    "        Candidate answer: a planet\n",
    "        Suggestion: a star is the correct option since the context clearly specifies that the Sun is the star at the center of the Solar System\n",
    "        Context: The Sun is the star at the center of the Solar System. It is a massive, nearly perfect sphere of hot plasma, heated to incandescence by nuclear fusion reactions in its core, radiating the energy from its surface mainly as visible light and infrared radiation with 10% at ultraviolet energies.\n",
    "\n",
    "        Assistant: the correct option is 'a star', since the suggestion is grounded in the context, even if the candidate answer does not agree.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\"role\": \"system\", \"content\": \"Now do the same for the following question:\"},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def preSynthGeneration(query, candidate_answer, critique, merged, sources):\n",
    "    prompt = create_message_presynthesis(query, merged, candidate_answer, critique, sources)\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    return output[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe2291b-5961-41dd-af73-1290d53da65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesisGeneration(query, merged, pre_answer, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = synthesis_chain.invoke({'question': query, \n",
    "                                            'options': merged,\n",
    "                                            'critique': pre_answer,\n",
    "                                            'context': sources})\n",
    "\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    ans = new_model + normal_string + select(merged)\n",
    "    return str(ans)\n",
    "\n",
    "def extract_answer_synthesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"Assistant:\\n\")\n",
    "\n",
    "    \n",
    "    # Se l'indice è stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"Assistant:\\n\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c1a1953-0234-4513-82bf-d7b24f3403dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35fbefd725d49ef9218aa7c8977f116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5890b4f2a0424b884d6f87f7627b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d9c442323442e3992eebc2a40360a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b713d8a69f854f9a911edee5b51bde8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87016552b5e240c79259b23bc4df51ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d861659ed5b479bb035201b884f5890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9147dccf964543ade9080229950bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c5ec697ba6467ca573ae5e00a68f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ead73f42d64aa2b22525486e42443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast=False)\n",
    "new_model = models.Transformers(model, tokenizer, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e679fc5c-4c26-418d-b891-f495e9b1b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99d00b0b-9cab-455a-b075-4f5240044ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>options</th>\n",
       "      <th>sum_supports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What event did Juan Rossell participate in?</td>\n",
       "      <td>1996 summer olympics</td>\n",
       "      <td>['1996 summer olympics', 'olympic games', 'spo...</td>\n",
       "      <td>The 2004 Summer Olympic Games, held in Athens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What languages did John Osteen speak or write?</td>\n",
       "      <td>english</td>\n",
       "      <td>['english', 'greek', 'koine greek', 'nahuatl',...</td>\n",
       "      <td>Christianity is a monotheistic religion based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the parent taxon of Proaigialosaurus?</td>\n",
       "      <td>lepidosauria</td>\n",
       "      <td>['alligatoridae', 'amphibia', 'amphisbaenia', ...</td>\n",
       "      <td>Herpetology is the branch of zoology that stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the parent taxon of Australosuchus?</td>\n",
       "      <td>crocodilia</td>\n",
       "      <td>['animal', 'area', 'crocodile', 'crocodilia', ...</td>\n",
       "      <td>Mekosuchinae was a subfamily of crocodiles th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>What was the occupation of Cao Chong?</td>\n",
       "      <td>physicist</td>\n",
       "      <td>['academic', 'builder', 'chancellor', 'classic...</td>\n",
       "      <td>The Three Kingdoms period (220280) in China w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                                           query  \\\n",
       "0             0           0     What event did Juan Rossell participate in?   \n",
       "1             1           1  What languages did John Osteen speak or write?   \n",
       "2             2           2   What is the parent taxon of Proaigialosaurus?   \n",
       "3             3           3     What is the parent taxon of Australosuchus?   \n",
       "4             4           4           What was the occupation of Cao Chong?   \n",
       "\n",
       "                 answer                                            options  \\\n",
       "0  1996 summer olympics  ['1996 summer olympics', 'olympic games', 'spo...   \n",
       "1               english  ['english', 'greek', 'koine greek', 'nahuatl',...   \n",
       "2          lepidosauria  ['alligatoridae', 'amphibia', 'amphisbaenia', ...   \n",
       "3            crocodilia  ['animal', 'area', 'crocodile', 'crocodilia', ...   \n",
       "4             physicist  ['academic', 'builder', 'chancellor', 'classic...   \n",
       "\n",
       "                                        sum_supports  \n",
       "0   The 2004 Summer Olympic Games, held in Athens...  \n",
       "1   Christianity is a monotheistic religion based...  \n",
       "2   Herpetology is the branch of zoology that stu...  \n",
       "3   Mekosuchinae was a subfamily of crocodiles th...  \n",
       "4   The Three Kingdoms period (220280) in China w...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wikihop_dataset/wikihop-merged-summarized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7575e1-39e2-44ab-94cc-e2c23a29e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['sum_supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d49c274-24cd-4425-9fe4-206c763f1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rows = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93583acf-3392-4a3c-a93f-994361b43675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between academic, builder, chancellor, classics, confucian scholar, designer, duke, emperor, engineer, engineering, father, founder, general, king, leader, major, mathematician, military, official, peasant, physicist, physics, politician, prior, rebel, research, ruler, science, script, social reformer, socialist, sovereign, taiwan that best matches with the suggestion. \n",
       "\n",
       "Question: What was the occupation of Cao Chong?\n",
       "Context:  The correct answer is chancellor. The context provided discusses the Three Kingdoms period in China and mentions Cao Cao, who was a warlord during the late Eastern Han dynasty and the founder of the state of Cao Wei. The term chancellor is often used to describe a high-ranking official in ancient Chinese dynasties, and Cao Cao held this position. The other options do not align with the context provided. end\n",
       "Sources:  The Three Kingdoms period (220280) in China was marked by the competition for supremacy among the states of Wei, Shu, and Wu. Wu, also known as Eastern Wu, was founded by Sun Quan in 222 and declared independence from the Cao Wei state in 229. Sun Quan ruled as King of Wu until 229 and as Emperor of Wu until 252. The states capital was initially Jianye (present-day Nanjing, Jiangsu) but later moved to Wuchang (present-day Ezhou, Hubei). The state of Cao Wei was established by Cao Pi in 220, with its capital at Luoyang. Cao Weis authority weakened after the death of Cao Rui, leading to the rise of Sima Yi and his family. The state of Shu Han was founded by Liu Bei in 221, with its capital at Chengdu. The Yellow Turban Rebellion (184-205) marked a significant event in Taoisms history due to its association with secret Taoist societies. Japan, located off the eastern coast of Asia, is an island nation in the Pacific Ocean. The Qin dynasty (221206 BC) was the first unified Chinese empire, founded by Qin Shi Huang after conquering the other states during the Warring States period. The Warring States period (481403 BC) was a time of conflict that ended with the Qin dynastys victory in 221 BC. Archimedes of Syracuse was a renowned mathematician and scientist. The concept of buoyancy, or Archimedes principle, states that the upward force exerted on a submerged object is equal to the weight of the fluid displaced by the object. The state of Cao Wei was founded by Cao Cao, a warlord who rose to power during the late Eastern Han dynasty. Cao Caos son, Cao Pi, forced Emperor Xian to abdicate in his favor, establishing the Cao Wei state. Liu Bei declared himself emperor of Shu Han, while Sun\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>chan</span>cellor</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THESIS\n",
    "answers = []\n",
    "for i in range(N_rows):\n",
    "    answers.append(extract_answer_thesis(thesisGeneration(first_queries[i], possibilities[i], sources[i])))\n",
    "\n",
    "\n",
    "# ANTITHESIS\n",
    "ant_answers = []\n",
    "for i in range(N_rows):\n",
    "    ant_answers.append(antithesisGeneration(first_queries[i], possibilities[i], answers[i], sources[i]))\n",
    "\n",
    "# SYNTHESIS\n",
    "pre_answers = []\n",
    "for i in range(N_rows):\n",
    "    pre_answers.append(preSynthGeneration(first_queries[i], possibilities[i], answers[i], ant_answers[i], sources[i]))\n",
    "\n",
    "\n",
    "# format synthesis\n",
    "syn_answers = []\n",
    "for i in range(N_rows):\n",
    "    syn_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            pre_answers[i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f43d422-3418-4354-9c30-139536a15c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1996 summer olympics', 'english', 'reptile', 'crocodilia', 'chancellor']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6387c-abcb-4e3b-b565-340673d5db33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
