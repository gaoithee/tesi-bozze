{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acce921c-a8b1-477d-9e8f-85154f555336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bc2bad-0a17-44fe-8e2f-76c628395270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "from guidance import models, select\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#############################################\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text(text):\n",
    "    return re.sub(r\"[^\\w\\s.,!?\\-:;()]+\", '', text)\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text_final(text):\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"\\-:;()]+', '', text)  # Rimuove i caratteri speciali\n",
    "    text = re.sub(r\"['\\\"-]\", '', text)  # Rimuove apostrofi, virgolette e trattini\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    return text\n",
    "\n",
    "#############################################\n",
    "\n",
    "# prompts and similar things:\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# prompt augmentation for the (format of the) synthesis:\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"You are a multiple-choice question answering assistant.\n",
    "Choose the most proper option between {options} that best matches with the suggestion. \n",
    "\n",
    "Question: {question}\n",
    "Context: {critique}\n",
    "Sources: {context}\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    ")\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"options\": itemgetter(\"options\"), \n",
    "                \"critique\": itemgetter(\"critique\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "synthesis_chain = augmentation | prompt_template \n",
    "\n",
    "#############################################\n",
    "\n",
    "def create_message_thesis(question, options, context):\n",
    "    options_str = '\", \"'.join(options)\n",
    "    content = f\"\"\"\n",
    "\n",
    "    Now do the same for this question: \"{question}\", where options: [\"{options_str}\"]. Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = \"Answer to the following question: \" + question + \" providing one of these options as answer: \" + str(options) + \"Assistant:\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You have to provide helpful answers to the user’s questions based on the context: \n",
    "        \"\"\" + context},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def extract_answer_thesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"}]\")\n",
    "\n",
    "    \n",
    "    # Se l'indice è stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"}]\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\"\n",
    "\n",
    "def thesisGeneration(query, merged, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = create_message_thesis(query, merged, sources)\n",
    "    ans = new_model + str(augmented_prompt) + select(merged)\n",
    "    return str(ans)\n",
    "\n",
    "#############################################\n",
    "\n",
    "def create_message_antithesis(question, candidate, options, context):\n",
    "    options_str = '\", \"'.join(options)\n",
    "    content = f\"\"\"\n",
    "\n",
    "    Now do the same for this question: \"{question}\", where options: [\"{options_str}\"]. Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = \"Question: \" + question + \"\\n Options: \" + str(options) + \"\\n Candidate answer: \" + candidate + \"\\n Context: \" + context + \"\\n Assistant: \\n\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You are asked to determine the most correct answer for a given question, provided a set of possible options.\n",
    "        You also have at disposal a first tentative answer that you are required to check with respect to the question and the relevant context.\n",
    "        Your goal is to decree which is the most correct answer to the question between the available options.\n",
    "\n",
    "        Here's an example of how to do it:\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "        Question: Jane's Addiction and Weeping Willows, play which genre of music?\n",
    "        Options: ['indie', 'rock']\n",
    "        Candidate answer: rock\n",
    "        Context: Weeping Willows is a Swedish indie rock group that started in 1995. Jane's Addiction is an American rock band from Los Angeles, formed in 1985. The band consists of Perry Farrell (vocals), Dave Navarro (guitar), Stephen Perkins (drums) and Chris Chaney (bass).\n",
    "        Assistant: \n",
    "        \"\"\"\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": \"\"\"\n",
    "        The context mentions that Weeping Willows is a 'Swedish indie rock group' and Jane's Addiction is an 'American rock band'. Both bands are associated with the 'rock' genre, thus the correct answer is 'rock'.\n",
    "        \"\"\"\n",
    "        },\n",
    "        {\"role\": \"system\", \"content\": \"Now do the same for the following question:\"},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def antithesisGeneration(query, merged, candidate, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    prompt = create_message_antithesis(query, candidate, merged, sources)\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "#############################################\n",
    "\n",
    "def create_message_presynthesis(question, candidate, suggestion, options, context):\n",
    "\n",
    "    user_content = \"Question: \" + question + \"\\n Options: \" + str(options) + \"\\n Candidate answer: \" + candidate + \"\\n Suggestion: \" + suggestion + \"\\n Context: \" + context + \"\\n Assistant: \\n\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are an helpful AI assistant. You are asked to determine the most correct answer for a given question, provided a set of possible options.\n",
    "        You also have at disposal a first tentative answer and a suggestion on which is the correct answer.\n",
    "        Your goal is to decree which is the most correct answer to the question between the available options according to the context.\n",
    "\n",
    "        Here's a few examples on how to do it:\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "        Question: Jane's Addiction and Weeping Willows, play which genre of music?\n",
    "        Options: ['indie', 'rock']\n",
    "        Candidate answer: rock\n",
    "        Suggestion: The context mentions that Weeping Willows is a 'Swedish indie rock group' and Jane's Addiction is an 'American rock band'. Both bands are associated with the 'rock' genre, thus the correct answer is 'rock'.\n",
    "        Context: Weeping Willows is a Swedish indie rock group that started in 1995. Jane's Addiction is an American rock band from Los Angeles, formed in 1985. The band consists of Perry Farrell (vocals), Dave Navarro (guitar), Stephen Perkins (drums) and Chris Chaney (bass).\n",
    "\n",
    "\n",
    "        Assistant: Both the candidate answer and the suggestion agree on the fact that the correct option is 'rock'. Let's check on the context whether or not this is correct. Weeping Willows is an indie rock group, thus they make rock music; Jane's Addiction is a rock band. Consequently the context confirms that the genre performed by both bands is 'rock'. The correct option is 'rock'. \n",
    "        \"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "        Question: Between two tennis players Kim Clijsters and Mary Pierce, who is older?\n",
    "        Options: ['Kim Clijsters', 'Mary Pierce']\n",
    "        Candidate answer: kim clijsters\n",
    "        Suggestion: The correct answer is 'Mary Pierce' as she was born on 15 January 1975, which is earlier than Kim Clijsters who was born on 8 June 1983.\n",
    "        Context: Kim Antonie Lode Clijsters (] ; born 8 June 1983) is a Belgian former professional tennis player. Clijsters is a former world No. 1 in both singles and doubles. Mary Pierce (born 15 January 1975) is a French retired tennis professional who played on the Women's Tennis Association (WTA) tour. Born in Canada, she is a citizen of Canada, and the United States. Pierce played for France in team competitions and in the Olympics.\n",
    "        \n",
    "        Assistant: The candidate answer says that the older tennis player is kim clijsters, while the suggestion indicates mary pierce. The context provides the birth dates of both players, thus I can check which of the two options is correct. kim clijsters was born on 8 June 1983, and mary pierce was born on 15 January 1975. By comparing these dates, it's clear that mary pierce is older than kim clijsters. Thus the correct option is 'mary pierce'.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"system\", \"content\": \"Now do the same for the following question:\"},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def preSynthGeneration(query, candidate_answer, critique, merged, sources):\n",
    "    prompt = create_message_presynthesis(query, merged, candidate_answer, critique, sources)\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "#############################################\n",
    "\n",
    "def synthesisGeneration(query, merged, pre_answer, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = synthesis_chain.invoke({'question': query, \n",
    "                                            'options': merged,\n",
    "                                            'critique': pre_answer,\n",
    "                                            'context': sources})\n",
    "\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    ans = new_model + normal_string + select(merged)\n",
    "    return str(ans)\n",
    "\n",
    "def extract_answer_synthesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"Assistant:\\n\")\n",
    "\n",
    "    \n",
    "    # Se l'indice è stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"Assistant:\\n\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576e6dbe-3c46-4660-9ae1-ba2c698ee96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37135f6d11a34984a68915e25c8418cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast=False)\n",
    "new_model = models.Transformers(model, tokenizer, temperature=0.0)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1486b15-7f21-4b04-b3c1-9e343226e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../wikihop_dataset/wikihop-merged-summarized.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['sum_supports']\n",
    "\n",
    "N_rows = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa05b68-cc85-4830-893b-d36fa3026ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>[{&#x27;role&#x27;: &#x27;system&#x27;, &#x27;content&#x27;: &#x27;\\n        You are an helpful AI assistant. You have to provide helpful answers to the user’s questions based on the context: \\n         Christianity is a monotheistic religion based on the life and teachings of Jesus Christ. It is the largest religion in the world, with over 2 billion followers. Christians believe in one God and follow the teachings of Jesus Christ, who they believe is the Son of God and the savior of humanity.\\n\\nLakewood Church is a nondenominational charismatic Christian megachurch located in Houston, Texas. It is the largest congregation in the United States, with an average attendance of about 52,000 people per week. The church is led by Joel Osteen, who is the son of John Hillery Osteen, the founder and first pastor of Lakewood Church.\\n\\nMexico is a federal republic in North America, bordered by the United States, Guatemala, Belize, the Caribbean Sea, and the Pacific Ocean. It is the most populous Spanish-speaking country in the world and the second most populous country in Latin America. Mexico is a federation comprising 31 states and a federal district that is also its capital and most populous city.\\n\\nJohn Hillery Osteen founded Lakewood Church in Houston, Texas, in 1959. He served as the first pastor until his death in 1999. His son, Joel Osteen, succeeded him as pastor and continues to lead the church today.\\n\\nHouston is the most populous city in Texas and the fourth-most populous city in the United States. It is located in Southeast Texas near the Gulf of Mexico and is the seat of Harris County. Houston is the principal city of the Houston metropolitan area, which is the fifth-most populated metropolitan area in the United States.\\n\\nIn summary, Christianity is a monotheistic religion based on the life and teachings of Jesus Christ, with over 2 billion followers worldwide. Lakewood Church in Houston, Texas, is the largest congregation in the United States, led by Joel Osteen, the son of John Hillery Osteen, the founder and first pastor of the church. Houston is the most populous city in Texas and the fourth-most populous city in the United States, and is the principal city of the Houston metropolitan area. &lt;|end|&gt;&#x27;}, {&#x27;role&#x27;: &#x27;user&#x27;, &#x27;content&#x27;: &quot;Answer to the following question: What languages did John Osteen speak or write? providing one of these options as answer: [&#x27;english&#x27;, &#x27;greek&#x27;, &#x27;koine greek&#x27;, &#x27;nahuatl&#x27;, &#x27;spanish&#x27;]Assistant:&quot;}]<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>s</span>panish</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    }
   ],
   "source": [
    "# THESIS\n",
    "answers = []\n",
    "for i in range(N_rows):\n",
    "    answers.append(extract_answer_thesis(thesisGeneration(first_queries[i], possibilities[i], sources[i])))\n",
    "\n",
    "\n",
    "# ANTITHESIS\n",
    "ant_answers = []\n",
    "for i in range(N_rows):\n",
    "    ant_answers.append(antithesisGeneration(first_queries[i], possibilities[i], answers[i], sources[i]))\n",
    "\n",
    "# SYNTHESIS\n",
    "pre_answers = []\n",
    "for i in range(N_rows):\n",
    "    pre_answers.append(preSynthGeneration(first_queries[i], possibilities[i], answers[i], ant_answers[i], sources[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0f2541-2ace-4394-8528-fde8f89b1873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The context provided gives us information about Juan Miguel Rossell Milanes\\' participation in various sporting events. It specifically mentions that he won the gold medal in the men\\'s beach team competition at the 2003 Pan American Games and also represented Cuba at the 1996 and 2004 Summer Olympics. Given the options provided, the correct answer to the question \"What event did Juan Rossell participate in?\" is \\'1996 summer olympics\\'. This is because the context directly states that he represented Cuba at the 1996 Summer Olympics, which aligns with the option given. The other options, \\'olympic games\\' and\\'sport\\', are too broad and do not specifically refer to the event in question. <|end|>',\n",
       " ' The context provided does not mention any languages spoken or written by John Osteen. Therefore, based on the given information, it is not possible to determine the correct answer from the options provided. <|end|>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8691501-3188-4c52-8a0a-26bb3750e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
