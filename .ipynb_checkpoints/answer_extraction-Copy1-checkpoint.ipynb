{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4aad120c-7468-45a3-943a-6a8a6504f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mini = pd.read_csv('PEC-phimini-base-wikihop.csv')\n",
    "# two = pd.read_csv('base-gemma-2b-wikihop.csv')\n",
    "# nine = pd.read_csv('base-gemma-9b-wikihop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0954dd0a-9610-45d0-94a3-8de4c9774a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from guidance import models, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e3b677-a013-42f3-822e-cac3b3ca49a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>correct</th>\n",
       "      <th>thesis</th>\n",
       "      <th>antithesis</th>\n",
       "      <th>pre-synthesis</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What languages did John Osteen speak or write?</td>\n",
       "      <td>english</td>\n",
       "      <td>spanish</td>\n",
       "      <td>The correct answer should be 'english' and'spa...</td>\n",
       "      <td>The correct option is ['english','spanish'], s...</td>\n",
       "      <td>Christian\" derives from the Koine Greek word \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What was Thomas Pitt's role in the context of ...</td>\n",
       "      <td>fictional character</td>\n",
       "      <td>series</td>\n",
       "      <td>The correct answer should be 'protagonist' due...</td>\n",
       "      <td>The correct option is 'protagonist', since the...</td>\n",
       "      <td>Anne Perry (born 28 October 1938 as Juliet Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In which administrative territorial entity is ...</td>\n",
       "      <td>new york</td>\n",
       "      <td>south</td>\n",
       "      <td>The correct answer should be 'erie county' due...</td>\n",
       "      <td>The correct option is 'erie county', since the...</td>\n",
       "      <td>Key Center North Tower is a high-rise located ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How did Joe Don Looney meet his demise?</td>\n",
       "      <td>accident</td>\n",
       "      <td>accident</td>\n",
       "      <td>I couldn't find any information about a person...</td>\n",
       "      <td>The correct option is ['knockout'], since the ...</td>\n",
       "      <td>The National Football League (NFL) is a profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What sport did the Louisiana IceGators play?</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>hockey</td>\n",
       "      <td>The correct answer should be 'ice hockey' due ...</td>\n",
       "      <td>The correct option is 'ice hockey', since the ...</td>\n",
       "      <td>Professional ice hockey has existed since the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              query  \\\n",
       "0           0     What languages did John Osteen speak or write?   \n",
       "1           1  What was Thomas Pitt's role in the context of ...   \n",
       "2           2  In which administrative territorial entity is ...   \n",
       "3           3            How did Joe Don Looney meet his demise?   \n",
       "4           4       What sport did the Louisiana IceGators play?   \n",
       "\n",
       "               correct    thesis  \\\n",
       "0              english   spanish   \n",
       "1  fictional character    series   \n",
       "2             new york     south   \n",
       "3             accident  accident   \n",
       "4           ice hockey    hockey   \n",
       "\n",
       "                                          antithesis  \\\n",
       "0  The correct answer should be 'english' and'spa...   \n",
       "1  The correct answer should be 'protagonist' due...   \n",
       "2  The correct answer should be 'erie county' due...   \n",
       "3  I couldn't find any information about a person...   \n",
       "4  The correct answer should be 'ice hockey' due ...   \n",
       "\n",
       "                                       pre-synthesis  \\\n",
       "0  The correct option is ['english','spanish'], s...   \n",
       "1  The correct option is 'protagonist', since the...   \n",
       "2  The correct option is 'erie county', since the...   \n",
       "3  The correct option is ['knockout'], since the ...   \n",
       "4  The correct option is 'ice hockey', since the ...   \n",
       "\n",
       "                                             context  \n",
       "0  Christian\" derives from the Koine Greek word \"...  \n",
       "1  Anne Perry (born 28 October 1938 as Juliet Mar...  \n",
       "2  Key Center North Tower is a high-rise located ...  \n",
       "3  The National Football League (NFL) is a profes...  \n",
       "4  Professional ice hockey has existed since the ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c01fc2d-2fd0-4f64-846c-32ce8c98e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "# prompt augmentation for the (format of the) synthesis:\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"You are a multiple-choice question answering assistant.\n",
    "Choose the most proper option between {options} that best matches with the suggestion. \n",
    "\n",
    "Question: {question}\n",
    "Context: {critique}\n",
    "Sources: {context}\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    ")\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"options\": itemgetter(\"options\"), \n",
    "                \"critique\": itemgetter(\"critique\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "synthesis_chain = augmentation | prompt_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a959a18b-7bcc-4dc7-9fec-f7cd6ce38ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text(text):\n",
    "    return re.sub(r\"[^\\w\\s.,!?\\-:;()]+\", '', text)\n",
    "\n",
    "def synthesisGeneration(query, merged, pre_answer, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = synthesis_chain.invoke({'question': query, \n",
    "                                            'options': merged,\n",
    "                                            'critique': pre_answer,\n",
    "                                            'context': sources})\n",
    "\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    ans = new_model + normal_string + select(merged)\n",
    "    return str(ans)\n",
    "\n",
    "def extract_answer_synthesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"\\n\\nAssistant:\\n\")\n",
    "\n",
    "    \n",
    "    # Se l'indice Ã¨ stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"\\n\\nAssistant:\\n\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57f8c7b-00dd-4cbb-bfac-af836cb11774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91c7f7b3e6e41e69ffcaac50e38bec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/guidance/chat.py:73: UserWarning: Chat template {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
      "' }}{% else %}{{ eos_token }}{% endif %} was unable to be loaded directly into guidance.\n",
      "                        Defaulting to the ChatML format which may not be optimal for the selected model. \n",
      "                        For best results, create and pass in a `guidance.ChatTemplate` subclass for your model.\n",
      "  warnings.warn(f\"\"\"Chat template {chat_template} was unable to be loaded directly into guidance.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast=False)\n",
    "new_model = models.Transformers(model, tokenizer, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "148d1285-abda-4044-b99c-183f37b77b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hotpot-bridge-updated.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['correct']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['support']\n",
    "\n",
    "def clean_alternative_column(df):\n",
    "    # Assicurati che i valori siano stringhe e rimuovi gli spazi bianchi\n",
    "    df['alternative'] = df['alternative'].apply(lambda x: str(x).replace(' ', '') if isinstance(x, str) else x)\n",
    "    return df\n",
    "    \n",
    "df = clean_alternative_column(df)\n",
    "\n",
    "N_rows = len(df)\n",
    "\n",
    "possibilities = []\n",
    "for i in range(N_rows):\n",
    "    possibilities.append(str([correct_answers[i], df['alternative'][i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9367f6-3ef3-4053-9f3c-7ed91530509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wikihop_dataset/wikihop-merged-summarized-test.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['sum_supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc9893-e39e-49c5-8223-87063a53099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/saracandu/my_wikihop/train.csv\")\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f69e9be-bed1-41f7-9bed-f0f3af78601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('saracandu/hotpotQA_nli', split=\"train\", trust_remote_code=True)\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = dataset['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = dataset['answer']\n",
    "possibilities = dataset['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = dataset['passages']\n",
    "\n",
    "N_rows = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ebf898-8906-46c2-bf15-ff16026f1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('ultramega-test.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['new']\n",
    "\n",
    "N_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420f259c-9da3-43ae-8478-b8adaade1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('ultramega-test-bridge.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['correct']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['new']\n",
    "\n",
    "N_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03153b77-566b-4018-bbc4-d77cace5c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('ultramega-test-wikihop-0109.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer_y']\n",
    "possibilities = df['options_y']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['pecore']\n",
    "\n",
    "N_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c988b15f-4fc4-49f2-94bc-fdcacc81f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between 1987, 1999, 20, 2000, 2005 that best matches with the suggestion. \n",
       "\n",
       "Question: In which year was the artificial heart invented?\n",
       "Context:  The correct answer is 1999. The context provided mentions that The Stereo, a band started by Rory Phillips, released their debut album Three Hundred in the summer of 1999. The Artificial Heart is the current band Rory Phillips is a part of, but there is no mention of the year it was invented. The artificial heart is a medical device, not a band, and the context does not provide any information about its invention year. end\n",
       "Sources: Rory Allen Phillips is a founding member of punk-ska band, The Impossibles. Phillips also started The Stereo with Jamie Woolford of Animal Chin in 1999, and Slowreader with Impossibles bandmate Gabe Hascall in 2001. Phillips current band is The Artificial Heart. Some of his side projects include Imbrocos Are You My Lionkiller?; the 20goto10; Nineteen Ninety-Now; Amex; and a 2000-2005 mixtape under Rory Allen Phillips. The Stereo was a pop, rock and roll band started in early 1999 by former skapunk band frontmen Jamie Woolford (of Animal Chin) and Rory Phillips (of The Impossibles). The duo released their debut album Three Hundred in the summer of 1999. Animal Chin was a ska punk group from Minneapolis, Minnesota\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>1</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>9</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>9</span>9</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "syn_answers = []\n",
    "for i in range(len(df)):\n",
    "    syn_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['pre-synthesis'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7dd352ea-dd9d-443f-a36a-141e1af3d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between 1987, 1999, 20, 2000, 2005 that best matches with the suggestion. \n",
       "\n",
       "Question: In which year was the artificial heart invented?\n",
       "Context:  The correct answer should be 1999 as the context mentions that The Stereo, a band started by Rory Phillips, released their debut album Three Hundred in the summer of 1999. The Artificial Heart is the current band Rory Phillips is a part of, but there is no mention of the year it was invented. end\n",
       "Sources: Rory Allen Phillips is a founding member of punk-ska band, The Impossibles. Phillips also started The Stereo with Jamie Woolford of Animal Chin in 1999, and Slowreader with Impossibles bandmate Gabe Hascall in 2001. Phillips current band is The Artificial Heart. Some of his side projects include Imbrocos Are You My Lionkiller?; the 20goto10; Nineteen Ninety-Now; Amex; and a 2000-2005 mixtape under Rory Allen Phillips. The Stereo was a pop, rock and roll band started in early 1999 by former skapunk band frontmen Jamie Woolford (of Animal Chin) and Rory Phillips (of The Impossibles). The duo released their debut album Three Hundred in the summer of 1999. Animal Chin was a ska punk group from Minneapolis, Minnesota\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>1</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>9</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>9</span>9</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ant_answers = []\n",
    "for i in range(len(df)):\n",
    "    ant_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['antithesis'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0f4c60f-e0ce-408a-861c-db0083be9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between Dragonslayer, Swiss Family Robinson that best matches with the suggestion. \n",
       "\n",
       "Question: Which American film, Dragonslayer or Swiss Family Robinson, was shot outside London?\n",
       "Context: It seems there is no information about the question in the provided context. The context appears to be about plants, specifically the Melissa and Darmera peltata species. There is no mention of the American films Dragonslayer or Swiss Family Robinson. \n",
       "\n",
       "However, I can suggest that the question might be related to film production, and the context might be missing. If we consider general knowledge about the films, Dragonslayer (1981) was indeed shot in the UK, but Swiss Family Robinson (1960) was shot in the UK and also in Hawaii, but also in the UK.\n",
       "Sources: Melissa is a genus of perennial herbs in the Lamiaceae, native to Europe and Asia but cultivated and naturalized in many other places.\n",
       "The name Melissa is derived from the Greek word mÃ©lissa meaning honeybee, owing to the abundance of nectar in the flowers.\n",
       "Axillary spikes of white or yellowish flowers appear in the summer. Darmera peltata (Indian rhubarb or umbrella plant) is a flowering plant, the only species within the genus Darmera in the family Saxifragaceae.\n",
       "It is a slowly spreading rhizomatous perennial native to mountain streamsides in woodland in the western United States (southwestern Oregon to northwestern California), growing to 2 m tall by 1 m wide.\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Drag</span>onslayer</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_answers = []\n",
    "for i in range(len(df)):\n",
    "    cot_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['cot'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4dfb038-d112-40fc-9c7c-c1410952188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'query': first_queries,\n",
    "    'correct': correct_answers,\n",
    "    'thesis': mini['thesis'],\n",
    "    'pre-antithesis': mini['antithesis'],\n",
    "    'antithesis': ant_answers,\n",
    "    'pre-synthesis': mini['pre-synthesis'],\n",
    "#    'cot': mini['cot'],\n",
    "    'synthesis': syn_answers,\n",
    "    'context': sources\n",
    "} \n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d111b821-4727-44ce-ab03-dcf2b0783ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'query': first_queries,\n",
    "    'correct': correct_answers,\n",
    "#    'thesis': mini['thesis'],\n",
    "#    'pre-antithesis': mini['antithesis'],\n",
    "#    'antithesis': ant_answers,\n",
    "#    'pre-synthesis': mini['pre-synthesis'],\n",
    "    'cot': mini['cot'],\n",
    "    'synthesis': cot_answers,\n",
    "    'context': sources\n",
    "} \n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72854d3-4e69-4a0b-a1b8-ad8e60cbf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_final(text):\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"\\-:;()]+', '', text)  # Rimuove i caratteri speciali\n",
    "    text = re.sub(r\"['\\\"-]\", '', text)  # Rimuove apostrofi, virgolette e trattini\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c314bdb-36bd-44f4-91b6-d73d2f53eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la funzione alla colonna 'correct answer'\n",
    "df['correct'] = df['correct'].apply(clean_text_final)\n",
    "df['thesis'] = df['thesis'].apply(clean_text_final)\n",
    "df['antithesis'] = df['antithesis'].apply(clean_text_final)\n",
    "df['synthesis'] = df['synthesis'].apply(clean_text_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d164363-b06d-40e6-bd6c-6107c8379d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la funzione alla colonna 'correct answer'\n",
    "df['correct'] = df['correct'].apply(clean_text_final)\n",
    "# df['thesis'] = df['thesis'].apply(clean_text_final)\n",
    "# df['antithesis'] = df['antithesis'].apply(clean_text_final)\n",
    "df['synthesis'] = df['synthesis'].apply(clean_text_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d52b8113-0ae8-45a7-987e-e5237a2da836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>correct</th>\n",
       "      <th>thesis</th>\n",
       "      <th>pre-antithesis</th>\n",
       "      <th>antithesis</th>\n",
       "      <th>pre-synthesis</th>\n",
       "      <th>synthesis</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What languages did John Osteen speak or write?</td>\n",
       "      <td>english</td>\n",
       "      <td>spanish</td>\n",
       "      <td>The correct answer should be 'english' becaus...</td>\n",
       "      <td>english</td>\n",
       "      <td>The correct answer is 'english'. The context ...</td>\n",
       "      <td>english</td>\n",
       "      <td>Christian\" derives from the Koine Greek word \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was Thomas Pitt's role in the context of ...</td>\n",
       "      <td>fictional character</td>\n",
       "      <td>year</td>\n",
       "      <td>The correct answer should be 'fictional chara...</td>\n",
       "      <td>fictional character</td>\n",
       "      <td>the correct option is 'fictional character', ...</td>\n",
       "      <td>fictional character</td>\n",
       "      <td>Anne Perry (born 28 October 1938 as Juliet Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In which administrative territorial entity is ...</td>\n",
       "      <td>new york</td>\n",
       "      <td>north</td>\n",
       "      <td>The correct answer should be 'Buffalo' as it ...</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>The correct option is 'Buffalo'. The context ...</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>Key Center North Tower is a high-rise located ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Joe Don Looney meet his demise?</td>\n",
       "      <td>accident</td>\n",
       "      <td>accident</td>\n",
       "      <td>The correct answer should be 'accident' as th...</td>\n",
       "      <td>accident</td>\n",
       "      <td>The correct answer is 'accident'. The context...</td>\n",
       "      <td>accident</td>\n",
       "      <td>The National Football League (NFL) is a profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sport did the Louisiana IceGators play?</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>The correct answer should be 'ice hockey' as ...</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>The correct option is 'ice hockey', as the co...</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>Professional ice hockey has existed since the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query              correct  \\\n",
       "0     What languages did John Osteen speak or write?              english   \n",
       "1  What was Thomas Pitt's role in the context of ...  fictional character   \n",
       "2  In which administrative territorial entity is ...             new york   \n",
       "3            How did Joe Don Looney meet his demise?             accident   \n",
       "4       What sport did the Louisiana IceGators play?           ice hockey   \n",
       "\n",
       "       thesis                                     pre-antithesis  \\\n",
       "0     spanish   The correct answer should be 'english' becaus...   \n",
       "1        year   The correct answer should be 'fictional chara...   \n",
       "2       north   The correct answer should be 'Buffalo' as it ...   \n",
       "3    accident   The correct answer should be 'accident' as th...   \n",
       "4  ice hockey   The correct answer should be 'ice hockey' as ...   \n",
       "\n",
       "            antithesis                                      pre-synthesis  \\\n",
       "0              english   The correct answer is 'english'. The context ...   \n",
       "1  fictional character   the correct option is 'fictional character', ...   \n",
       "2              buffalo   The correct option is 'Buffalo'. The context ...   \n",
       "3             accident   The correct answer is 'accident'. The context...   \n",
       "4           ice hockey   The correct option is 'ice hockey', as the co...   \n",
       "\n",
       "             synthesis                                            context  \n",
       "0              english  Christian\" derives from the Koine Greek word \"...  \n",
       "1  fictional character  Anne Perry (born 28 October 1938 as Juliet Mar...  \n",
       "2              buffalo  Key Center North Tower is a high-rise located ...  \n",
       "3             accident  The National Football League (NFL) is a profes...  \n",
       "4           ice hockey  Professional ice hockey has existed since the ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7b01b28-d61d-471d-adbe-c2b91965c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PEC-phimini-base-wikihop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad463d8-c0ce-4469-a052-c5f02e5506ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5988457-0ca3-45dd-986a-52460681eee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e48e7-a1bb-45a2-8cb1-cb19a2f999a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
