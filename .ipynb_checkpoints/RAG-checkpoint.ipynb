{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a268f4e1-3a6d-464d-885b-2053e3143a2f",
   "metadata": {},
   "source": [
    "# Dataset, documents, FAISS; retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db4863-a54b-4d3a-87e2-74c645fcc018",
   "metadata": {},
   "source": [
    "## üîπ Load the dataset containing the tuples `(query, correct_answer, distractor_1, distractor_2)` and the one containing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094ab87a-0ba8-4878-991e-01515de302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers', 'correct_answer', 'distractor_1', 'distractor_2'],\n",
       "    num_rows: 82326\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('saracandu/msmarco_modified', split=\"train\", trust_remote_code=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856a910c-be2a-440f-8cab-c0faac78af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='\"Since 2007, the RBA\\'s outstanding reputation has been affected by the \\'Securency\\' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA\\'s employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "\n",
    "loader = HuggingFaceDatasetLoader('saracandu/msmarco_filtered', 'passage_text')\n",
    "documents = loader.load()\n",
    "documents[0] # just to check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045746d4-d0d6-4cf1-b68e-63bebe72f990",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üîπ Turn `documents` into a vector database using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626e646-9fb4-4235-8858-edb8a898f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# create an instance of the RecursiveCharacterTextSplitter class with specific parameters\n",
    "# (it splits text into chunks of 50 characters each with a 20-character overlap)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "\n",
    "# 'documents' holds the text you want to split, split the text into documents using the text splitter\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91fa4f-156e-45dc-a6fa-2b89489b891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an embedding method\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbce37-535e-4952-a076-683e009b9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the documents 'docs' into vectors using the embedding method specified by 'embedding'\n",
    "# the result is stored in a FAISS index:\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# to avoid computing it each time (since the docs won't change), save the result in the storage\n",
    "db.save_local(folder_path=\"faiss_db\", index_name=\"MSMARCO_FaissIndex_MPNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17955f64-8650-4095-860e-5b818bd6a833",
   "metadata": {},
   "source": [
    "## üîπ Upload the already existing vector database (if it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbc054f-ab89-47dd-941f-d002e62abcf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.6.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/multi-qa-MiniLM-L6-dot-v1\",  \n",
    ")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    folder_path=\"faiss_db\", # where to find it\n",
    "    embeddings=embeddings, # in which \"embedding language\" it is expressed\n",
    "    index_name=\"MSMARCO_FaissIndex_MiniLM\", # since the folder contains multiple vector databases, specify its name\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5babae8-e52e-4046-9a29-e886bb5f4b22",
   "metadata": {},
   "source": [
    "## üîπ Use it as a `retriever`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061a230-7d28-4693-89ce-d4fad815925f",
   "metadata": {},
   "source": [
    "**Note:** `'k'=10` specifies the number of documents to retrieve each time `retrieved` is invoked. \n",
    "The default type of search performed is `similarity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e800071b-4968-4c0a-818d-16534f44d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_kwargs={'k': 1,}\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895debf-b05f-4bbf-aa4f-c9f32aa693d9",
   "metadata": {},
   "source": [
    "Why `'k'=10`? Because MSMARCO assigns to each `(query, answer)` pair 10 text passages, and only 1 or 2 of these are truly relevant. \n",
    "In this first step of analysis I chose not to create `len(dataset)` different vector databases, one for each `(query, answer)` pair, but instead to merge all the passages together and store them into an unique vector database. \n",
    "\n",
    "\n",
    "**SE `'k'=10` SBAGLIA ALCUNE RISPOSTE! SE LO ABBASSI A `3` O A `4` NO :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bb532-fa37-4cfe-89fa-731ad140276d",
   "metadata": {},
   "source": [
    "# Model part (`Llama-2-7b-chat-hf`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86132ec0-f0d0-4316-b71e-92af9861cda2",
   "metadata": {},
   "source": [
    "## ‚ñ™Ô∏è Upload the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce89a37-b6e1-48ff-b8fb-621e456392c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run this unless necessary!\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6eb0bf-fb11-4952-b14e-809b77898a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f95abbed724d78b086c32e185a9a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d17128d-7b94-4e6a-9ba2-95a8dc2d4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlines import models\n",
    "\n",
    "new_model = models.Transformers(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0545fee1-7acd-4c85-8f01-5cff7fdc7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "prompt = \"\"\"You are a sentiment-labelling assistant.\n",
    "Is the following review positive or negative?\n",
    "\n",
    "Review: This restaurant is just awesome!\n",
    "\"\"\"\n",
    "\n",
    "generator = outlines.generate.choice(new_model, [\"Positive\", \"Negative\"])\n",
    "answer = generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021dac4c-df3d-4e50-b09d-5314ee8bd317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cc29e-5f6a-440e-a5fd-8a5bee3050f6",
   "metadata": {},
   "source": [
    "## ‚ñ™Ô∏è Select a subset of the true dataset as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61598fb6-67e3-4d06-94bf-892f4330ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a subset of the queries, just for test:\n",
    "first_queries = dataset['query'][:200]\n",
    "# first_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e058aac-3fa5-42b7-95db-809669ac8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for correct answers and distractors:\n",
    "correct_answers = dataset['correct_answer'][:200]\n",
    "distractors_1 = dataset['distractor_1'][:200]\n",
    "distractors_2 = dataset['distractor_2'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae0973bd-82ec-48f3-98a1-8f603bc80149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Results-Based Accountability is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.']\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e39db-091e-4510-800a-0a16f2b89e76",
   "metadata": {},
   "source": [
    "## ‚ñ™Ô∏è Merge the true answer and the distractors into a vector, shuffling the order of the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab974ea-41f0-44b3-8167-592bbd323320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffles the order of the vector containing the correct answer and the two distractors\n",
    "# returns another vector, shuffled\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s.,!?\\'\"\\-:;()]+', '', text)\n",
    "\n",
    "# Funzione per mescolare le risposte\n",
    "def shuffleAnswers(correct_answer, distractor_1, distractor_2):\n",
    "    # Applica la pulizia a ciascun elemento\n",
    "    correct_answer_cleaned = clean_text(correct_answer)\n",
    "    distractor_1_cleaned = clean_text(distractor_1)\n",
    "    distractor_2_cleaned = clean_text(distractor_2)\n",
    "    \n",
    "    # Unisci le opzioni pulite\n",
    "    merge_options = [correct_answer_cleaned, distractor_1_cleaned, distractor_2_cleaned]\n",
    "    \n",
    "    # Mescola le opzioni\n",
    "    random.shuffle(merge_options)\n",
    "    \n",
    "    return merge_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d43a34-fc04-4043-afcb-c8271f6a4e3f",
   "metadata": {},
   "source": [
    "## ‚ñ™Ô∏è Function to format them properly the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38b14ba-0d52-4ca3-806c-a7dd8241e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function to format properly the output of the retrieval step\n",
    "\n",
    "def format_page_content(documents):\n",
    "    \"\"\"\n",
    "    Formats the list of retrieved documents such that 'page_content', 'Documents', 'metadata' \n",
    "    words are removed and just the true content is kept.\n",
    "    \"\"\"\n",
    "    formatted_output = \"\"\n",
    "    for i, doc in enumerate(documents, start=1):\n",
    "        content = doc.page_content.strip(\" \")\n",
    "        formatted_output += f\"[{i}]: {content}\\n\"\n",
    "    return formatted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722aa12-2d2a-4868-83ef-96f01617d4d7",
   "metadata": {},
   "source": [
    "## üîπ PromptTemplate definition and a LLMChain for the **thesis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7751aac-b970-455b-b2b4-4b8575aad07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template definition\n",
    "# requires question, options (a string containing the possible options) and the context as input variables!\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    You're a helpful assistant and you are asked to answer a question correctly, given a certain number of options. \n",
    "    Answer with the correct option only and then stop.\n",
    "    Given this question: {question} you have to answer given only one of the following options: {option_a}, {option_b}, {option_c}. \\n\n",
    "    Here is context to help: {context} \\n\n",
    "    The correct answer is:\n",
    " \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ad711e-db35-47d4-8949-ffedc071f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain definition\n",
    "from operator import itemgetter\n",
    "\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"option_a\": itemgetter(\"option_a\"), \n",
    "                \"option_b\": itemgetter(\"option_b\"),\n",
    "                \"option_c\": itemgetter(\"option_c\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "\n",
    "thesis_chain = augmentation | prompt_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df44c274-1fea-484d-925c-4c0729fd9079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\n    You're a helpful assistant and you are asked to answer a question correctly, given a certain number of options. \\n    Answer with the correct option only and then stop.\\n    Given this question: query you have to answer given only one of the following options: a, b, c. \\n\\n    Here is context to help: something \\n\\n    The correct answer is:\\n \")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thesis_chain.invoke({'question': 'query', 'option_a': 'a', 'option_b': 'b', 'option_c': 'c', 'context': 'something'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc84e0-fa8c-404d-85b4-96be5448a81d",
   "metadata": {},
   "source": [
    "## üîπ Function that generates the output given the prompt, the question and the set of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ca079d-d85c-491f-87ab-2a0dfd626894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "def thesisGeneration(query, merged):\n",
    "    documents_retrieved = retriever.invoke(query)\n",
    "    formatted_context = format_page_content(documents_retrieved)\n",
    "    augmented_prompt = thesis_chain.invoke({'question': query, 'option_a': merged[0], 'option_b': merged[1], 'option_c': merged[2], 'context': formatted_context})\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    options = [merged[0], merged[1], merged[2]]\n",
    "    generator = outlines.generate.choice(new_model, options)\n",
    "    answer = generator(normal_string)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf177e-3d1d-4e08-96d3-c9bf9144c986",
   "metadata": {},
   "source": [
    "## üîπ Test: how well the thesis alone is able to perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c65767f-ef49-4f37-8a8e-7810529ef08c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'append' of type ListType[Tuple(array([unichr x 2], 1d, A), array(int64, 1d, A))]\n\nFile \"../nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py\", line 82:\ndef _append(l, item):\n    l.append(item)\n    ^\n\nDuring: typing of get attribute at /orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py (82)\n\nFile \"../nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py\", line 82:\ndef _append(l, item):\n    l.append(item)\n    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m      3\u001b[0m     merged_options \u001b[38;5;241m=\u001b[39m shuffleAnswers(correct_answers[i], distractors_1[i], distractors_2[i])\n\u001b[0;32m----> 4\u001b[0m     answers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mthesisGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_queries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_options\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mthesisGeneration\u001b[0;34m(query, merged)\u001b[0m\n\u001b[1;32m      7\u001b[0m normal_string \u001b[38;5;241m=\u001b[39m clean_text(augmented_prompt\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      8\u001b[0m options \u001b[38;5;241m=\u001b[39m [merged[\u001b[38;5;241m0\u001b[39m], merged[\u001b[38;5;241m1\u001b[39m], merged[\u001b[38;5;241m2\u001b[39m]]\n\u001b[0;32m----> 9\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43moutlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m answer \u001b[38;5;241m=\u001b[39m generator(normal_string)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/generate/choice.py:17\u001b[0m, in \u001b[0;36mchoice\u001b[0;34m(model, choices, sampler)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoice\u001b[39m(\n\u001b[1;32m     13\u001b[0m     model, choices: List[\u001b[38;5;28mstr\u001b[39m], sampler: Sampler \u001b[38;5;241m=\u001b[39m multinomial()\n\u001b[1;32m     14\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequenceGenerator:\n\u001b[1;32m     15\u001b[0m     regex_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(choices) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[43mregex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     generator\u001b[38;5;241m.\u001b[39mformat_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generator\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/generate/regex.py:32\u001b[0m, in \u001b[0;36mregex\u001b[0;34m(model, regex_str, sampler)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregex\u001b[39m(model, regex_str: \u001b[38;5;28mstr\u001b[39m, sampler: Sampler \u001b[38;5;241m=\u001b[39m multinomial()):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate structured text in the language of a regular expression.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     fsm \u001b[38;5;241m=\u001b[39m \u001b[43mRegexGuide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     device \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     35\u001b[0m     generator \u001b[38;5;241m=\u001b[39m SequenceGenerator(fsm, model, sampler, device)\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/fsm/guide.py:145\u001b[0m, in \u001b[0;36mRegexGuide.__init__\u001b[0;34m(self, regex_string, tokenizer)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, regex_string: \u001b[38;5;28mstr\u001b[39m, tokenizer):\n\u001b[1;32m    141\u001b[0m     (\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates_to_token_maps,\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty_token_ids,\n\u001b[1;32m    144\u001b[0m         fsm_finals,\n\u001b[0;32m--> 145\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_states_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_states \u001b[38;5;241m=\u001b[39m fsm_finals \u001b[38;5;241m|\u001b[39m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m}\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/caching.py:122\u001b[0m, in \u001b[0;36mcache.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m result \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39m__memory__\u001b[38;5;241m.\u001b[39mget(cache_key, default\u001b[38;5;241m=\u001b[39mENOVAL, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m ENOVAL:\n\u001b[0;32m--> 122\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcached_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39m__memory__\u001b[38;5;241m.\u001b[39mset(cache_key, result, expire, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/fsm/guide.py:118\u001b[0m, in \u001b[0;36mcreate_states_mapping\u001b[0;34m(regex_string, tokenizer)\u001b[0m\n\u001b[1;32m    116\u001b[0m byte_fsm \u001b[38;5;241m=\u001b[39m make_byte_level_fsm(regex_pattern\u001b[38;5;241m.\u001b[39mto_fsm()\u001b[38;5;241m.\u001b[39mreduce(), keep_utf8\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    117\u001b[0m regex_fsm, _ \u001b[38;5;241m=\u001b[39m make_deterministic_fsm(byte_fsm)\n\u001b[0;32m--> 118\u001b[0m states_to_token_maps, empty_token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fsm_index_tokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregex_fsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# We make sure that it is possible to generate strings in the language\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# of the regular expression with the tokens present in the model's\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# vocabulary.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    126\u001b[0m     regex_fsm\u001b[38;5;241m.\u001b[39mfinals\u001b[38;5;241m.\u001b[39mintersection(v\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m states_to_token_maps\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    127\u001b[0m ):\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/fsm/regex.py:842\u001b[0m, in \u001b[0;36mcreate_fsm_index_tokenizer\u001b[0;34m(fsm, tokenizer)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_fsm_index_tokenizer\u001b[39m(\n\u001b[1;32m    830\u001b[0m     fsm: BetterFSM,\n\u001b[1;32m    831\u001b[0m     tokenizer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    832\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mint\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]], Set[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an FMS index from a tokenizer.\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    This uses the end-to-end approach of `create_fsm_index_end_to_end`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m \n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m     vocabulary, empty_token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mreduced_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m     states_to_token_subsets \u001b[38;5;241m=\u001b[39m create_fsm_index_end_to_end(fsm\u001b[38;5;241m.\u001b[39mfsm_info, vocabulary)\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m# Allow transitions to EOS from all terminals FSM states that are\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# reachable\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# TODO: Do we really need this anymore?\u001b[39;00m\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/outlines/fsm/regex.py:824\u001b[0m, in \u001b[0;36mreduced_vocabulary\u001b[0;34m(tokenizer)\u001b[0m\n\u001b[1;32m    822\u001b[0m     token_tuple_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromiter(token_tuple, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU2\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    823\u001b[0m     token_ids_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromiter(token_ids, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 824\u001b[0m     \u001b[43mvocabulary_nb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_tuple_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_ids_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vocabulary_nb, empty_token_ids\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py:344\u001b[0m, in \u001b[0;36mList.append\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typed:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialise_list(item)\n\u001b[0;32m--> 344\u001b[0m \u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtyping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'append' of type ListType[Tuple(array([unichr x 2], 1d, A), array(int64, 1d, A))]\n\nFile \"../nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py\", line 82:\ndef _append(l, item):\n    l.append(item)\n    ^\n\nDuring: typing of get attribute at /orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py (82)\n\nFile \"../nlp-env/lib64/python3.9/site-packages/numba/typed/typedlist.py\", line 82:\ndef _append(l, item):\n    l.append(item)\n    ^\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for i in range(200):\n",
    "    merged_options = shuffleAnswers(correct_answers[i], distractors_1[i], distractors_2[i])\n",
    "    answers.append(thesisGeneration(first_queries[i], merged_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cf43b76-0053-472b-9ced-325492f127f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Results-Based Accountability is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.'\",\n",
       " \"'A contamination which is associated with the food itself and not through other causes of contamination.'\",\n",
       " \"'20-25 minutes'\",\n",
       " \"'11 to 22 per square foot'\",\n",
       " \"'Due to symptoms in the body'\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc7617-7074-49ec-a1db-2d86416aeca2",
   "metadata": {},
   "source": [
    "## üî∏ PromptTemplate definition and a LLMChain for the **antithesis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "310428aa-b58f-4b51-8c56-839d19951d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "antithesis_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=False,\n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.5,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=400,\n",
    "    top_p=0.0\n",
    ")\n",
    "\n",
    "antithesis_llm = HuggingFacePipeline(pipeline=antithesis_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8451da76-fc21-44f2-81a5-64eabe0ade4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    You're a helpful assistant and you are asked to check whether or not a question was answered correctly, given a certain number of candidate options and the context. \n",
    "    Given this question: {question} you have to check is the following candidate answer: {candidate_answer}.\n",
    "    You have to answer by saying 'Yes' if it is correct and 'No' otherwise, then explain why you think so. \n",
    "    Think carefully of the all the possible options: {option_a}, {option_b}, {option_c} and say if one of them seems to you more appropriate than the candidate.\n",
    "    Here is context to help: {context} \\n\n",
    "    Why or why not the answer is correct:\n",
    " \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66388c99-daad-4de1-9188-cafc15857a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain definition\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"option_a\": itemgetter(\"option_a\"), \n",
    "                \"option_b\": itemgetter(\"option_b\"),\n",
    "                \"option_c\": itemgetter(\"option_c\"),\n",
    "                \"candidate_answer\": itemgetter(\"candidate_answer\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "\n",
    "antithesis_chain = augmentation | prompt_template | antithesis_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643ed8f-0d35-44b4-84cd-293816c40ed4",
   "metadata": {},
   "source": [
    "## üî∏ Function to generate the antithesis given the question, the thesis, the context and the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ef1b239-4d92-473a-89a7-42ee0137f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antithesisGeneration(query, prompt_template, merged, candidate_answer):\n",
    "    documents_retrieved = retriever.invoke(query)\n",
    "    formatted_context = format_page_content(documents_retrieved)\n",
    "    \n",
    "    second_answer = antithesis_chain.invoke({'question': query, \n",
    "                                            'option_a': merged[0], 'option_b': merged[1], 'option_c': merged[2], \n",
    "                                            'candidate_answer': candidate_answer,\n",
    "                                            'context': formatted_context})\n",
    "    return second_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821f2559-ab56-4769-811e-569be6a609b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_ant(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"Why or why not the answer is correct:\")\n",
    "    \n",
    "    # Se l'indice √® stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"Why or why not the answer is correct:\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d4639f-6f79-4d9e-be69-03b02a2c5b40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'antithesis_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# print(f\"True answer: {correct_answers[i]}\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     merged_options \u001b[38;5;241m=\u001b[39m shuffleAnswers(correct_answers[i], distractors_1[i], distractors_2[i])\n\u001b[0;32m----> 5\u001b[0m     ant_answers\u001b[38;5;241m.\u001b[39mappend(extract_answer_ant(\u001b[43mantithesisGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_queries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# print(f\"Given answer: {extract_answer_ant(antithesisGeneration(first_queries[i], prompt_template, merged_options, answers[i]))}\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print('****************')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m, in \u001b[0;36mantithesisGeneration\u001b[0;34m(query, prompt_template, merged, candidate_answer)\u001b[0m\n\u001b[1;32m      2\u001b[0m documents_retrieved \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39minvoke(query)\n\u001b[1;32m      3\u001b[0m formatted_context \u001b[38;5;241m=\u001b[39m format_page_content(documents_retrieved)\n\u001b[0;32m----> 5\u001b[0m second_answer \u001b[38;5;241m=\u001b[39m \u001b[43mantithesis_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: query, \n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_a\u001b[39m\u001b[38;5;124m'\u001b[39m: merged[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_b\u001b[39m\u001b[38;5;124m'\u001b[39m: merged[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_c\u001b[39m\u001b[38;5;124m'\u001b[39m: merged[\u001b[38;5;241m2\u001b[39m], \n\u001b[1;32m      7\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidate_answer\u001b[39m\u001b[38;5;124m'\u001b[39m: candidate_answer,\n\u001b[1;32m      8\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: formatted_context})\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m second_answer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'antithesis_chain' is not defined"
     ]
    }
   ],
   "source": [
    "ant_answers = []\n",
    "for i in range(200):\n",
    "    # print(f\"True answer: {correct_answers[i]}\")\n",
    "    merged_options = shuffleAnswers(correct_answers[i], distractors_1[i], distractors_2[i])\n",
    "    ant_answers.append(extract_answer_ant(antithesisGeneration(first_queries[i], prompt_template, merged_options, answers[i])))\n",
    "    # print(f\"Given answer: {extract_answer_ant(antithesisGeneration(first_queries[i], prompt_template, merged_options, answers[i]))}\")\n",
    "    # print('****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "679251ac-6945-4ff2-9b89-0c349662bc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes - This option matches exactly how Results Based Accounting (RBA) works according to their website description provided above; they state themselves being an organization focused on helping businesses create better user experience through strategic planning using both tech solutions while also providing evidence based results tracking for accountable decision making purposes within organizations across industries such as healthcare providers etcetera thus align perfectly well together under umbrella term called Digital Transformation Consultants who focus solely upon enhancing customer satisfaction via seamless integration between human centered approach alongside cutting edge technologies designed exclusively around meeting client needs more efficiently than ever before possible!',\n",
       " 'I would say yes because according to what has been provided in the text \"Ronald Regan\" as an example for someone who switched from being Democratic party member too republicans.',\n",
       " 'I agree with your assessment because \"Surrounding Areas Sydney\". It means all places around Sidney including its suburbs which would take more than just few hours like less than half an hour as suggested in option A (20‚Äì25 min)',\n",
       " 'Yes - This option matches what we were told for how much installing tiles costs on average.\"',\n",
       " 'Yes - This option matches what I found when researching \"conversion observation\". Conversions can occur due to various factors such as genetic mutations leading to changes at DNA level which may result into observable physical traits like size shape color etcetera; exposure too environmental pollutants radiation UV light chemicals pesticides heavy metals drugs alcohol smoking cigarettes ecterae causing damage within cells tissues organs systems eventually resulting visible signs abnormalities behaviors patterns health issues disorders diseases conditions syndromes birth defects cancer tumors neurological problems psychological distress anxiety depression schizophrenia bipolar manic episodes personality disorder obsessive compulsions phobias addictions substance use dependence withdrawal sepsis shock organ failure cardiac arrest respiratory collapse comas vegetative state minimally conscious states locked-inchief executive officer (CEO) brain dead condition where patient cannot breathe on their own without life support machines..']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1edb95-c057-4d4b-8a40-c24f578e6c6b",
   "metadata": {},
   "source": [
    "## üî∫ PromptTemplate definition and a LLMChain for the **synthesis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091cee6-41d3-4164-804e-f6c492e88745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    You're a helpful assistant and you are asked to answer a certain question, given a certain number of candidate options and the context.\n",
    "    You are also provided with an initial response and its critique, that could enforce or not the first opinion.\n",
    "    Make a reasonable synthesis of these two opinions, but answer by outputting exactly one of the answer options only.\n",
    "    Given this question: {question} you have to answer given only one of the following options: {option_a}, {option_b}, {option_c}. \\n\n",
    "    The answer that you have to check is {candidate_answer} and this is its critique: {critique}. \n",
    "    If the critique is not happy with the previous answer, correct it with another of the available options.\n",
    "    Here is context to help: {context} \\n\n",
    "    The answer is:\n",
    " \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4d68c-5e0e-4818-89cb-93e1731ec3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain definition\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"option_a\": itemgetter(\"option_a\"), \n",
    "                \"option_b\": itemgetter(\"option_b\"),\n",
    "                \"option_c\": itemgetter(\"option_c\"),\n",
    "                \"candidate_answer\": itemgetter(\"candidate_answer\"),\n",
    "                \"critique\": itemgetter(\"critique\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "\n",
    "synthesis_chain = augmentation | prompt_template "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170bc0d-1182-4c31-b33d-65fe64e1c385",
   "metadata": {},
   "source": [
    "## üî∫ Function to generate the synthesis given literally everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bef727-d240-4511-a556-0d2c19db4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesisGeneration(query, prompt_template, merged, candidate_answer, critique):\n",
    "    documents_retrieved = retriever.invoke(query)\n",
    "    formatted_context = format_page_content(documents_retrieved)\n",
    "    \n",
    "    augmented_prompt = synthesis_chain.invoke({'question': query, \n",
    "                                            'option_a': merged[0], 'option_b': merged[1], 'option_c': merged[2], \n",
    "                                            'candidate_answer': candidate_answer,\n",
    "                                            'critique': critique,\n",
    "                                            'context': formatted_context})\n",
    "\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    options = [merged[0], merged[1], merged[2]]\n",
    "    generator = outlines.generate.choice(new_model, options)\n",
    "    final_answer = generator(normal_string)\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4286d7-99cf-4f0c-a320-d9b3c6f84863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "syn_answers = []\n",
    "for i in range(200):\n",
    "    merged_options = shuffleAnswers(correct_answers[i], distractors_1[i], distractors_2[i])\n",
    "    syn_answers.append(synthesisGeneration(first_queries[i], prompt_template, merged_options, answers[i], ant_answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3176f-7f6b-4c55-a4da-c984771bca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new = {'query': first_queries, 'correct answer': correct_answers, 'thesis': answers, 'antithesis': ant_answers, 'synthesis': syn_answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae959b96-7e8f-445e-8ddb-94e0a49116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fcd8b-db5f-4d4a-b816-b043a28d2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ee61af5-3cfd-4aa9-971e-81a8d7d44831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('first_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3741b36-c57c-4d5a-b435-d9fefa71ab6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
