{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aad120c-7468-45a3-943a-6a8a6504f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mini = pd.read_csv('PEC-phimini-ctx-bridge.csv')\n",
    "# two = pd.read_csv('base-gemma-2b-wikihop.csv')\n",
    "# nine = pd.read_csv('base-gemma-9b-wikihop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0954dd0a-9610-45d0-94a3-8de4c9774a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from guidance import models, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e3b677-a013-42f3-822e-cac3b3ca49a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>correct</th>\n",
       "      <th>thesis</th>\n",
       "      <th>antithesis</th>\n",
       "      <th>pre-synthesis</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>delhi</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>The context clearly states that The Oberoi Gr...</td>\n",
       "      <td>The Oberoi family is associated with The Ober...</td>\n",
       "      <td>The Oberoi family is an Indian family that is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>president richard nixon</td>\n",
       "      <td>president abraham lincoln</td>\n",
       "      <td>The context clearly states that Milhouse Muss...</td>\n",
       "      <td>The correct answer is 'President Richard Nixo...</td>\n",
       "      <td>She is co-host of Everything's Coming Up Podca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>american</td>\n",
       "      <td>british</td>\n",
       "      <td>The context states that James Henry Miller, a...</td>\n",
       "      <td>The context clearly states that James Henry M...</td>\n",
       "      <td>James Henry Miller (25 January 1915 – 22 Octob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>sodium chloride</td>\n",
       "      <td>The context states that Cadmium Chloride is s...</td>\n",
       "      <td>The context clearly states that Cadmium Chlor...</td>\n",
       "      <td>It is a hygroscopic solid that is highly solub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which genus of moth in the world's seventh-lar...</td>\n",
       "      <td>crambidae</td>\n",
       "      <td>lepidoptera</td>\n",
       "      <td>The context states that Indogrammodes is a ge...</td>\n",
       "      <td>The context provided mentions that Indogrammo...</td>\n",
       "      <td>India's Andaman and Nicobar Islands share a ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              query  \\\n",
       "0           0  The Oberoi family is part of a hotel company t...   \n",
       "1           1  Musician and satirist Allie Goertz wrote a son...   \n",
       "2           2    What nationality was James Henry Miller's wife?   \n",
       "3           3  Cadmium Chloride is slightly soluble in this c...   \n",
       "4           4  Which genus of moth in the world's seventh-lar...   \n",
       "\n",
       "                   correct                     thesis  \\\n",
       "0                    delhi                     mumbai   \n",
       "1  president richard nixon  president abraham lincoln   \n",
       "2                 american                    british   \n",
       "3                  alcohol            sodium chloride   \n",
       "4                crambidae                lepidoptera   \n",
       "\n",
       "                                          antithesis  \\\n",
       "0   The context clearly states that The Oberoi Gr...   \n",
       "1   The context clearly states that Milhouse Muss...   \n",
       "2   The context states that James Henry Miller, a...   \n",
       "3   The context states that Cadmium Chloride is s...   \n",
       "4   The context states that Indogrammodes is a ge...   \n",
       "\n",
       "                                       pre-synthesis  \\\n",
       "0   The Oberoi family is associated with The Ober...   \n",
       "1   The correct answer is 'President Richard Nixo...   \n",
       "2   The context clearly states that James Henry M...   \n",
       "3   The context clearly states that Cadmium Chlor...   \n",
       "4   The context provided mentions that Indogrammo...   \n",
       "\n",
       "                                             context  \n",
       "0  The Oberoi family is an Indian family that is ...  \n",
       "1  She is co-host of Everything's Coming Up Podca...  \n",
       "2  James Henry Miller (25 January 1915 – 22 Octob...  \n",
       "3  It is a hygroscopic solid that is highly solub...  \n",
       "4  India's Andaman and Nicobar Islands share a ma...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c01fc2d-2fd0-4f64-846c-32ce8c98e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "# prompt augmentation for the (format of the) synthesis:\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"You are a multiple-choice question answering assistant.\n",
    "Choose the most proper option between {options} that best matches with the suggestion. \n",
    "\n",
    "Question: {question}\n",
    "Context: {critique}\n",
    "Sources: {context}\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    ")\n",
    "augmentation = {\"question\": itemgetter(\"question\"),\n",
    "                \"options\": itemgetter(\"options\"), \n",
    "                \"critique\": itemgetter(\"critique\"),\n",
    "                \"context\": itemgetter(\"context\"), }\n",
    "synthesis_chain = augmentation | prompt_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a959a18b-7bcc-4dc7-9fec-f7cd6ce38ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "# Definisci una funzione di pulizia per rimuovere caratteri non validi\n",
    "def clean_text(text):\n",
    "    return re.sub(r\"[^\\w\\s.,!?\\-:;()]+\", '', text)\n",
    "\n",
    "def synthesisGeneration(query, merged, pre_answer, sources):\n",
    "    merged = ast.literal_eval(merged)\n",
    "    augmented_prompt = synthesis_chain.invoke({'question': query, \n",
    "                                            'options': merged,\n",
    "                                            'critique': pre_answer,\n",
    "                                            'context': sources})\n",
    "\n",
    "    normal_string = clean_text(augmented_prompt.text)\n",
    "    ans = new_model + normal_string + select(merged)\n",
    "    return str(ans)\n",
    "\n",
    "def extract_answer_synthesis(text):\n",
    "    # Trova l'indice in cui inizia il testo \"Why or why not the answer is correct:\"\n",
    "    start_index = text.find(\"\\n\\nAssistant:\\n\")\n",
    "\n",
    "    \n",
    "    # Se l'indice è stato trovato, estrai la risposta corretta\n",
    "    if start_index != -1:\n",
    "        start_index += len(\"\\n\\nAssistant:\\n\")\n",
    "        # Estrai il testo dopo \"Why or why not the answer is correct:\"\n",
    "        correct_answer_text = text[start_index:].strip()\n",
    "        return correct_answer_text\n",
    "    else:\n",
    "        return \"The correct answer could not be found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57f8c7b-00dd-4cbb-bfac-af836cb11774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca42eab1c43749a5bae0eb6aa907fbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/guidance/chat.py:73: UserWarning: Chat template {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
      "' }}{% else %}{{ eos_token }}{% endif %} was unable to be loaded directly into guidance.\n",
      "                        Defaulting to the ChatML format which may not be optimal for the selected model. \n",
      "                        For best results, create and pass in a `guidance.ChatTemplate` subclass for your model.\n",
      "  warnings.warn(f\"\"\"Chat template {chat_template} was unable to be loaded directly into guidance.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast=False)\n",
    "new_model = models.Transformers(model, tokenizer, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d1285-abda-4044-b99c-183f37b77b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hotpot-bridge-updated.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['correct']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['support']\n",
    "\n",
    "def clean_alternative_column(df):\n",
    "    # Assicurati che i valori siano stringhe e rimuovi gli spazi bianchi\n",
    "    df['alternative'] = df['alternative'].apply(lambda x: str(x).replace(' ', '') if isinstance(x, str) else x)\n",
    "    return df\n",
    "    \n",
    "df = clean_alternative_column(df)\n",
    "\n",
    "N_rows = len(df)\n",
    "\n",
    "possibilities = []\n",
    "for i in range(N_rows):\n",
    "    possibilities.append(str([correct_answers[i], df['alternative'][i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9367f6-3ef3-4053-9f3c-7ed91530509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wikihop_dataset/wikihop-merged-summarized-test.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['sum_supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc9893-e39e-49c5-8223-87063a53099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/saracandu/my_wikihop/train.csv\")\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['query']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f69e9be-bed1-41f7-9bed-f0f3af78601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('saracandu/hotpotQA_nli', split=\"train\", trust_remote_code=True)\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = dataset['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = dataset['answer']\n",
    "possibilities = dataset['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = dataset['passages']\n",
    "\n",
    "N_rows = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ebf898-8906-46c2-bf15-ff16026f1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('ultramega-test.csv')\n",
    "\n",
    "# select a subset of the queries, just for test:\n",
    "first_queries = df['question']\n",
    "\n",
    "# same for correct answers and distractors:\n",
    "correct_answers = df['answer']\n",
    "possibilities = df['options']\n",
    "\n",
    "# and for the sources:\n",
    "sources = df['new']\n",
    "\n",
    "N_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c988b15f-4fc4-49f2-94bc-fdcacc81f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between Dragonslayer, Swiss Family Robinson that best matches with the suggestion. \n",
       "\n",
       "Question: Which American film, Dragonslayer or Swiss Family Robinson, was shot outside London?\n",
       "Context:  Question: Which plant is native to mountain streamsides in woodland in the western United States?\n",
       "Options: Melissa, Darmera peltata\n",
       "Candidate answer: Darmera peltata\n",
       "Suggestion: Darmera peltata is the correct option since the context clearly specifies that it is native to mountain streamsides in woodland in the western United States.\n",
       "Context: Darmera peltata (Indian rhubarb or umbrella plant) is a flowering plant, the only species within the genus Darmera in the family Saxifragaceae. It is a slowly spreading rhizomatous perennial native to mountain streamsides in woodland in the western United States (southwestern Oregon to northwestern California), growing to 2 m tall by 1 m wide.\n",
       "\n",
       "Assistant: The correct option is Darmera peltata, as the context provided indicates that it is native to mountain streamsides in woodland in the western United States. end\n",
       "Sources: Melissa is a genus of perennial herbs in the Lamiaceae, native to Europe and Asia but cultivated and naturalized in many other places.\n",
       "The name Melissa is derived from the Greek word mélissa meaning honeybee, owing to the abundance of nectar in the flowers.\n",
       "Axillary spikes of white or yellowish flowers appear in the summer. Darmera peltata (Indian rhubarb or umbrella plant) is a flowering plant, the only species within the genus Darmera in the family Saxifragaceae.\n",
       "It is a slowly spreading rhizomatous perennial native to mountain streamsides in woodland in the western United States (southwestern Oregon to northwestern California), growing to 2 m tall by 1 m wide.\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Drag</span>onslayer</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "syn_answers = []\n",
    "for i in range(len(df)):\n",
    "    syn_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['pre-synthesis'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd352ea-dd9d-443f-a36a-141e1af3d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between Dragonslayer, Swiss Family Robinson that best matches with the suggestion. \n",
       "\n",
       "Question: Which American film, Dragonslayer or Swiss Family Robinson, was shot outside London?\n",
       "Context:  Assistant: The context provided does not seem to be related to the question about the American film shot outside London. However, if we look at the options, Dragonslayer is a fantasy film directed by John Dykstra and starring Peter MacNicol, while Swiss Family Robinson is a family adventure film directed by Robert Stevenson.\n",
       "\n",
       "Dragonslayer was indeed filmed in various locations outside London, including the United States and Canada. On the other hand, Swiss Family Robinson was primarily filmed in the United Kingdom, including locations in London.\n",
       "\n",
       "Therefore, based on the information provided, the correct answer is Dragonslayer. end\n",
       "Sources: Melissa is a genus of perennial herbs in the Lamiaceae, native to Europe and Asia but cultivated and naturalized in many other places.\n",
       "The name Melissa is derived from the Greek word mélissa meaning honeybee, owing to the abundance of nectar in the flowers.\n",
       "Axillary spikes of white or yellowish flowers appear in the summer. Darmera peltata (Indian rhubarb or umbrella plant) is a flowering plant, the only species within the genus Darmera in the family Saxifragaceae.\n",
       "It is a slowly spreading rhizomatous perennial native to mountain streamsides in woodland in the western United States (southwestern Oregon to northwestern California), growing to 2 m tall by 1 m wide.\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Drag</span>onslayer</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ant_answers = []\n",
    "for i in range(len(df)):\n",
    "    ant_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['antithesis'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f4c60f-e0ce-408a-861c-db0083be9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>You are a multiple-choice question answering assistant.\n",
       "Choose the most proper option between Dragonslayer, Swiss Family Robinson that best matches with the suggestion. \n",
       "\n",
       "Question: Which American film, Dragonslayer or Swiss Family Robinson, was shot outside London?\n",
       "Context:  The context provided does not seem to directly relate to the question about the American film Dragonslayer or Swiss Family Robinson. However, we can still use the information given to deduce the correct answer.\n",
       "\n",
       "Dragonslayer is a 1981 American fantasy film directed by John Nicolella and starring Peter MacNicol, and it was indeed shot in various locations outside London, including the United Kingdom and Spain.\n",
       "\n",
       "On the other hand, Swiss Family Robinson is a 1960 American adventure film directed by Kurt Neumann and based on the 1812 novel by Johann Wyss. The film was shot entirely in the United States, with no locations outside London.\n",
       "\n",
       "Therefore, the correct option is Dragonslayer. end\n",
       "Sources: Melissa is a genus of perennial herbs in the Lamiaceae, native to Europe and Asia but cultivated and naturalized in many other places.\n",
       "The name Melissa is derived from the Greek word mélissa meaning honeybee, owing to the abundance of nectar in the flowers.\n",
       "Axillary spikes of white or yellowish flowers appear in the summer. Darmera peltata (Indian rhubarb or umbrella plant) is a flowering plant, the only species within the genus Darmera in the family Saxifragaceae.\n",
       "It is a slowly spreading rhizomatous perennial native to mountain streamsides in woodland in the western United States (southwestern Oregon to northwestern California), growing to 2 m tall by 1 m wide.\n",
       "\n",
       "Assistant:\n",
       "<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Drag</span>onslayer</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_answers = []\n",
    "for i in range(len(df)):\n",
    "    cot_answers.append(extract_answer_synthesis(\n",
    "        synthesisGeneration(\n",
    "            first_queries[i], possibilities[i], \n",
    "            mini['cot'][i], sources[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4dfb038-d112-40fc-9c7c-c1410952188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'query': first_queries,\n",
    "    'correct': correct_answers,\n",
    "    'thesis': mini['thesis'],\n",
    "    'pre-antithesis': mini['antithesis'],\n",
    "    'antithesis': ant_answers,\n",
    "    'pre-synthesis': mini['pre-synthesis'],\n",
    "#    'cot': mini['cot'],\n",
    "    'synthesis': syn_answers,\n",
    "    'context': sources\n",
    "} \n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d111b821-4727-44ce-ab03-dcf2b0783ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'query': first_queries,\n",
    "    'correct': correct_answers,\n",
    "#    'thesis': mini['thesis'],\n",
    "#    'pre-antithesis': mini['antithesis'],\n",
    "#    'antithesis': ant_answers,\n",
    "#    'pre-synthesis': mini['pre-synthesis'],\n",
    "    'cot': mini['cot'],\n",
    "    'synthesis': cot_answers,\n",
    "    'context': sources\n",
    "} \n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72854d3-4e69-4a0b-a1b8-ad8e60cbf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_final(text):\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"\\-:;()]+', '', text)  # Rimuove i caratteri speciali\n",
    "    text = re.sub(r\"['\\\"-]\", '', text)  # Rimuove apostrofi, virgolette e trattini\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c314bdb-36bd-44f4-91b6-d73d2f53eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la funzione alla colonna 'correct answer'\n",
    "df['correct'] = df['correct'].apply(clean_text_final)\n",
    "df['thesis'] = df['thesis'].apply(clean_text_final)\n",
    "df['antithesis'] = df['antithesis'].apply(clean_text_final)\n",
    "df['synthesis'] = df['synthesis'].apply(clean_text_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d164363-b06d-40e6-bd6c-6107c8379d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la funzione alla colonna 'correct answer'\n",
    "df['correct'] = df['correct'].apply(clean_text_final)\n",
    "# df['thesis'] = df['thesis'].apply(clean_text_final)\n",
    "# df['antithesis'] = df['antithesis'].apply(clean_text_final)\n",
    "df['synthesis'] = df['synthesis'].apply(clean_text_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52b8113-0ae8-45a7-987e-e5237a2da836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>correct</th>\n",
       "      <th>cot</th>\n",
       "      <th>synthesis</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which magazine was started first, Arthur's Mag...</td>\n",
       "      <td>arthurs magazine</td>\n",
       "      <td>Let's analyze the options and the context pro...</td>\n",
       "      <td>arthurs magazine</td>\n",
       "      <td>Arthur's Magazine (1844–1846) was an American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which tennis player won more Grand Slam titles...</td>\n",
       "      <td>jonathan stark</td>\n",
       "      <td>To answer this question, we need to compare t...</td>\n",
       "      <td>jonathan stark</td>\n",
       "      <td>Henri Leconte (born 4 July 1963) is a former F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which band was founded first, Hole (the rock b...</td>\n",
       "      <td>the wolfhounds</td>\n",
       "      <td>Assistant: The context provides information a...</td>\n",
       "      <td>the wolfhounds</td>\n",
       "      <td>The Wolfhounds are an indie pop/noise pop band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Were Pavel Urysohn and Leonid Levin known for ...</td>\n",
       "      <td>no</td>\n",
       "      <td>Assistant: The context provides information a...</td>\n",
       "      <td>no</td>\n",
       "      <td>Leonid Anatolievich Levin ( ; Russian: Леони́д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are both The New Pornographers and Kings of Le...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Let's analyze the options and the context pro...</td>\n",
       "      <td>no</td>\n",
       "      <td>Kings of Leon is an American rock band that fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query           correct  \\\n",
       "0  Which magazine was started first, Arthur's Mag...  arthurs magazine   \n",
       "1  Which tennis player won more Grand Slam titles...    jonathan stark   \n",
       "2  Which band was founded first, Hole (the rock b...    the wolfhounds   \n",
       "3  Were Pavel Urysohn and Leonid Levin known for ...                no   \n",
       "4  Are both The New Pornographers and Kings of Le...               yes   \n",
       "\n",
       "                                                 cot         synthesis  \\\n",
       "0   Let's analyze the options and the context pro...  arthurs magazine   \n",
       "1   To answer this question, we need to compare t...    jonathan stark   \n",
       "2   Assistant: The context provides information a...    the wolfhounds   \n",
       "3   Assistant: The context provides information a...                no   \n",
       "4   Let's analyze the options and the context pro...                no   \n",
       "\n",
       "                                             context  \n",
       "0  Arthur's Magazine (1844–1846) was an American ...  \n",
       "1  Henri Leconte (born 4 July 1963) is a former F...  \n",
       "2  The Wolfhounds are an indie pop/noise pop band...  \n",
       "3  Leonid Anatolievich Levin ( ; Russian: Леони́д...  \n",
       "4  Kings of Leon is an American rock band that fo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b01b28-d61d-471d-adbe-c2b91965c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PEC-phimini-purecot-hotpotqa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad463d8-c0ce-4469-a052-c5f02e5506ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5988457-0ca3-45dd-986a-52460681eee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e48e7-a1bb-45a2-8cb1-cb19a2f999a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
